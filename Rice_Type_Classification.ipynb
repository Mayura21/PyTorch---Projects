{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6hlWnZA2m-19"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/mssmartypants/rice-type-classification\")"
      ],
      "metadata": {
        "id": "ZMaPcl12nEvT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGy5XUsNnSCC",
        "outputId": "7b68d43f-04af-412c-c735-f99a95dce511"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv(\"/content/rice-type-classification/riceClassification.csv\")\n",
        "data_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tuKxspP0w89L",
        "outputId": "e5148b21-bfb6-4d31-dda5-6a66f50d9c30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/rice-type-classification/riceClassification.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2260299200.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/rice-type-classification/riceClassification.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/rice-type-classification/riceClassification.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.info()"
      ],
      "metadata": {
        "id": "DZ61ff6yxu-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.describe()"
      ],
      "metadata": {
        "id": "HuQ6Y3NmxxZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.isnull().sum()"
      ],
      "metadata": {
        "id": "8dJ_2bAmx1Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.dropna(inplace=True)\n",
        "data_df.drop(columns=['id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Xl3VsU7Xx7PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "mK7C7Ux5yKCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.head()"
      ],
      "metadata": {
        "id": "W69YSCTeyLVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.Class.unique()"
      ],
      "metadata": {
        "id": "unyWgdSEySKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.Class.value_counts()"
      ],
      "metadata": {
        "id": "ZqkmjuiYyfjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df = data_df.copy()"
      ],
      "metadata": {
        "id": "0kd39Fxgymea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data_df.columns:\n",
        "  data_df[column] = data_df[column] / data_df[column].abs().max()\n",
        "\n",
        "data_df.head()"
      ],
      "metadata": {
        "id": "IMEMJQH4zVBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(data_df.iloc[:, :-1])\n",
        "y = np.array(data_df.iloc[:, -1])"
      ],
      "metadata": {
        "id": "jlb2SVfNznzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "yIdvzJuR7AE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, X_val, y_test, y_val = tts(X_test, y_test, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "7yWZmXws7H1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ],
      "metadata": {
        "id": "q6CGXYUP8Nkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "dvOtiDdd8U-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "GO2v2HidBLjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val"
      ],
      "metadata": {
        "id": "jzHhfOa8BMi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    self.y = torch.tensor(y, dtype=torch.float32).to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]"
      ],
      "metadata": {
        "id": "v6tjI_AwBNlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = dataset(X_train, y_train)\n",
        "validation_data = dataset(X_val, y_val)\n",
        "testing_data = dataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "gfQCsj4QDMM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "id": "7XP7hTauEOgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(validation_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "uDDb6gFYES9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_dataloader:\n",
        "  print(X)\n",
        "  print(\"==================\")\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "id": "d_7xHJy9FPuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_NEURONS = 10\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    self.input_layer = nn.Linear(X.shape[1], HIDDEN_NEURONS)\n",
        "    self.linear = nn.Linear(HIDDEN_NEURONS, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    x = self.input_layer(X)\n",
        "    x = self.linear(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "qG_ueq3MFahn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel().to(device)"
      ],
      "metadata": {
        "id": "uyg5EDX6Lok5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (X.shape[1], ))"
      ],
      "metadata": {
        "id": "LjoH-1kSLwZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "YPiur-9CL5tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss_train_plot = []\n",
        "total_loss_val_plot = []\n",
        "total_acc_train_plot = []\n",
        "total_acc_val_plot = []\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_acc_train = 0\n",
        "  total_loss_train = 0\n",
        "  total_acc_val = 0\n",
        "  total_loss_val = 0\n",
        "\n",
        "  for data in train_dataloader:\n",
        "    inputs, labels = data\n",
        "\n",
        "    prediction = model(inputs).squeeze(1)\n",
        "\n",
        "    batch_loss = criterion(prediction, labels)\n",
        "    total_loss_train += batch_loss.item()\n",
        "\n",
        "    acc = ((prediction).round() == labels).sum().item()\n",
        "    total_acc_train += acc\n",
        "\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  with torch.no_grad():\n",
        "    for data in val_dataloader:\n",
        "      inputs, labels = data\n",
        "\n",
        "      prediction = model(inputs).squeeze(1)\n",
        "      batch_loss = criterion(prediction, labels)\n",
        "      total_loss_val += batch_loss.item()\n",
        "\n",
        "      acc = ((prediction).round() == labels).sum().item()\n",
        "      total_acc_val += acc\n",
        "    total_loss_train_plot.append(round(total_loss_train/1000, 4))\n",
        "    total_loss_val_plot.append(round(total_loss_val/1000, 4))\n",
        "    total_acc_train_plot.append(round(total_acc_train/training_data.__len__() * 100, 4))\n",
        "    total_acc_val_plot.append(round(total_acc_val/validation_data.__len__() * 100, 4))\n",
        "\n",
        "    print(f\"\"\"Epoch no {epoch + 1}\n",
        "          Train Loss:      {round(total_loss_train/1000, 4)}\\t\\t Train Accuracy:    {round(total_acc_train/training_data.__len__() * 100, 4)}\n",
        "          Validation Loss: {round(total_loss_val/1000, 4)}\\t\\t Validation Accuracy: {round(total_acc_val/validation_data.__len__() * 100, 4)}\"\"\")\n",
        "    print(\"=\"*80)"
      ],
      "metadata": {
        "id": "RXwfuDWclX6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  total_loss_test = 0\n",
        "  total_acc_test = 0\n",
        "  for data in test_dataloader:\n",
        "    inputs, labels = data\n",
        "\n",
        "    prediction = model(inputs).squeeze(1)\n",
        "\n",
        "    batch_loss = criterion(prediction, labels)\n",
        "    total_loss_test += batch_loss.item()\n",
        "\n",
        "    acc = ((prediction).round() == labels).sum().item()\n",
        "    total_acc_test += acc\n",
        "\n",
        "print(f\"Accuracy: {round(total_acc_test / testing_data.__len__() * 100, 4)}\")"
      ],
      "metadata": {
        "id": "3ibE4gjVnsc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "axs[0].plot(total_loss_train_plot, label = \"Training Loss\")\n",
        "axs[0].plot(total_loss_val_plot, label = \"Validation Loss\")\n",
        "axs[0].set_title(\"Training and Validation loss over epochs\")\n",
        "axs[0].set_xlabel(\"Epochs\")\n",
        "axs[0].set_ylabel(\"Loss\")\n",
        "axs[0].set_ylim([0, 0.1])\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(total_acc_train_plot, label = \"Training Accuracy\")\n",
        "axs[1].plot(total_acc_val_plot, label = \"Validation Accuracy\")\n",
        "axs[1].set_title(\"Training and Validation Accuracy over epochs\")\n",
        "axs[1].set_xlabel(\"Epochs\")\n",
        "axs[1].set_ylabel(\"Accuracy\")\n",
        "axs[1].set_ylim([97, 100])\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iY-kNSvyqXK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df.head()"
      ],
      "metadata": {
        "id": "sepzZGA9P6rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "area = 6284 / original_df['Area'].abs().max()\n",
        "MajorAxisLength =  81 / original_df['MajorAxisLength'].abs().max()\n",
        "MinorAxisLength =  42 / original_df['MinorAxisLength'].abs().max()\n",
        "Eccentricity =  0.98 / original_df['Eccentricity'].abs().max()\n",
        "ConvexArea =  1200 / original_df['ConvexArea'].abs().max()\n",
        "EquivDiameter =  33 / original_df['EquivDiameter'].abs().max()\n",
        "Extent =  0.7 / original_df['Extent'].abs().max()\n",
        "Perimeter =  927 / original_df['Perimeter'].abs().max()\n",
        "Roundness =  0.9 / original_df['Roundness'].abs().max()\n",
        "AspectRation =  1.45 / original_df['AspectRation'].abs().max()\n"
      ],
      "metadata": {
        "id": "HJDYUjWrN7D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(torch.tensor([area, MajorAxisLength, MinorAxisLength, Eccentricity, ConvexArea, EquivDiameter, Extent, Perimeter, Roundness, AspectRation], dtype=torch.float32).to(device))"
      ],
      "metadata": {
        "id": "BwSvXD8RPTtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "U1YO5lVNVM1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.item()"
      ],
      "metadata": {
        "id": "-ZU7lrl1VNtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(pred.item())"
      ],
      "metadata": {
        "id": "6nAO-IaQVT9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCFJuD7jVXTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Jz2z8Dsl1SSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}